{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2 по обработке текстов\n",
    "\n",
    "Рассмотрим задачу бинарной классификации. Пусть дано два списка имен: мужские и женские имена. Требуется разработать классификатор, который по данному имени будет определять мужское оно или женское.\n",
    "\n",
    "Данные: \n",
    "* Женские имена: female.txt\n",
    "* Мужские имена: male.txt\n",
    "\n",
    "## Часть 1. Предварительная обработка данных\n",
    "\n",
    "1. Удалите неоднозначные имена (те имена, которые являются и мужскими, и женскими дновременно), если такие есть; \n",
    "2. Создайте обучающее и тестовое множество так, чтобы в обучающем множестве классы были сбалансированы, т.е. к классу принадлежало бы одинаковое количество имен;\n",
    "\n",
    "##  Часть 2. Базовый метод классификации\n",
    "\n",
    "Используйте метод наивного Байеса или логистическую регрессию для классификации имен: в качестве признаков используйте символьные $n$-граммы. Сравните результаты, получаемые при разных $n=2,3,4$ по $F$-мере и аккуратности. В каких случаях метод ошибается?\n",
    "\n",
    "Для генерации $n$-грамм используйте:\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "DATA_DIR='names_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Читаем данные и заполняем списки\n",
    "females = read_file('female.txt')\n",
    "males   = read_file('male.txt')\n",
    "females_uniq = np.setdiff1d(females, males)\n",
    "males_uniq = np.setdiff1d(males, females)\n",
    "females_long = []\n",
    "for i in females_uniq:\n",
    "    if len(i) < 4:\n",
    "     #   print(i)\n",
    "        True\n",
    "    else:\n",
    "        females_long.append(i)\n",
    "        \n",
    "males_long = []\n",
    "for i in males_uniq:\n",
    "    if len(i) < 4:\n",
    "     #   print(i)\n",
    "        True\n",
    "    else:\n",
    "        males_long.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 2000\n",
    "TEST_SIZE = 440\n",
    "NGRAM_SIZE = 3\n",
    "\n",
    "#m_females = females\n",
    "#m_males   = males\n",
    "\n",
    "# Для обучения только на уникальных именах\n",
    "m_females = females_uniq\n",
    "m_males   = males_uniq\n",
    "\n",
    "\n",
    "# Обучение на именах, длиннее 4 символов.\n",
    "#m_females = females_long\n",
    "#m_males =   males_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_train, female_test = train_test_split(m_females, train_size = TRAIN_SIZE, test_size = TEST_SIZE)\n",
    "male_train, male_test = train_test_split(m_males, train_size = TRAIN_SIZE, test_size = TEST_SIZE)\n",
    "\n",
    "X_train_names = np.concatenate((female_train, male_train))\n",
    "X_test_names = np.concatenate((female_test, male_test))\n",
    "\n",
    "y_train = np.concatenate((np.zeros(TRAIN_SIZE),np.ones(TRAIN_SIZE))) \n",
    "y_test = np.concatenate((np.zeros(TEST_SIZE), np.ones(TEST_SIZE)))\n",
    "\n",
    "X_train_ngrams = get_ngrams_list(X_train_names,NGRAM_SIZE)\n",
    "X_test_ngrams = get_ngrams_list(X_test_names, NGRAM_SIZE)\n",
    "\n",
    "cv = CountVectorizer(analyzer='word')\n",
    "cv.fit(X_train_ngrams)\n",
    "X_train = cv.transform(X_train_ngrams)\n",
    "X_test = cv.transform(X_test_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2629)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_Scores\n",
      "acc=0.8662\n",
      "micro F1=0.8662, micro P=0.8662, micro R=0.4630, micro RC=0.8662\n",
      "macro F1=0.8661, macro P=0.8662, macro R=0.4630, macro RC=0.8676 \n",
      "\n",
      "TEST_Scores\n",
      "acc=0.7795\n",
      "micro F1=0.7795, micro P=0.7795, micro R=0.1066, micro RC=0.7795\n",
      "macro F1=0.7788, macro P=0.7795, macro R=0.1066, macro RC=0.7832 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "MNB_clf = MultinomialNB(alpha=2)\n",
    "MNB_clf.fit(X_train, y_train)\n",
    "train_predicted = MNB_clf.predict(X_train)\n",
    "print(\"TRAIN_Scores\")\n",
    "print_scores(train_predicted, y_train)\n",
    "print(\"TEST_Scores\")\n",
    "print_scores(MNB_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие показатели для N-грамм из трех символов: на тестовой выборек  accuracy = 0.7864, F1=0.7863 при alpha = 1. <br>\n",
    "Для N-грамм из 3 символов -  accuracy  = 0.7795, F1 = 0.7788<br>\n",
    "Для N-грамм из 2 символов -  accuracy  = 0.7307, F1 = 0.7303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выведем список ошибочных предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = Codie; predicted = 1.0\n",
      "name = Tiffie; predicted = 1.0\n",
      "name = Esther; predicted = 1.0\n",
      "name = Hester; predicted = 1.0\n",
      "name = Kellsie; predicted = 1.0\n",
      "name = Olive; predicted = 1.0\n",
      "name = Gera; predicted = 1.0\n",
      "name = Vilma; predicted = 1.0\n",
      "name = Jeniffer; predicted = 1.0\n",
      "name = Neilla; predicted = 1.0\n",
      "name = Kiele; predicted = 1.0\n",
      "name = Thia; predicted = 1.0\n",
      "name = Aili; predicted = 1.0\n",
      "name = Desdemona; predicted = 1.0\n",
      "name = Kevina; predicted = 1.0\n",
      "name = Steffie; predicted = 1.0\n",
      "name = Andromache; predicted = 1.0\n",
      "name = Allison; predicted = 1.0\n",
      "name = Ericka; predicted = 1.0\n",
      "name = Farand; predicted = 1.0\n",
      "name = Delphine; predicted = 1.0\n",
      "name = Micki; predicted = 1.0\n",
      "name = Sylvie; predicted = 1.0\n",
      "name = Fortuna; predicted = 1.0\n",
      "name = Veradis; predicted = 1.0\n",
      "name = Constancy; predicted = 1.0\n",
      "name = Cariotta; predicted = 1.0\n",
      "name = Andromeda; predicted = 1.0\n",
      "name = Mikako; predicted = 1.0\n",
      "name = Quintilla; predicted = 1.0\n",
      "name = Francoise; predicted = 1.0\n",
      "name = Frances; predicted = 1.0\n",
      "name = Ericha; predicted = 1.0\n",
      "name = Fern; predicted = 1.0\n",
      "name = Phillis; predicted = 1.0\n",
      "name = Merci; predicted = 1.0\n",
      "name = Elfrieda; predicted = 1.0\n",
      "name = Daria; predicted = 1.0\n",
      "name = Debera; predicted = 1.0\n",
      "name = Edee; predicted = 1.0\n",
      "name = Maisey; predicted = 1.0\n",
      "name = Harriott; predicted = 1.0\n",
      "name = Christan; predicted = 1.0\n",
      "name = Wendy; predicted = 1.0\n",
      "name = Ingrid; predicted = 1.0\n",
      "name = Birdie; predicted = 1.0\n",
      "name = Ealasaid; predicted = 1.0\n",
      "name = Corny; predicted = 1.0\n",
      "name = Alexa; predicted = 1.0\n",
      "name = Rosmunda; predicted = 1.0\n",
      "name = Neille; predicted = 1.0\n",
      "name = Devina; predicted = 1.0\n",
      "name = Alberta; predicted = 1.0\n",
      "name = Nola; predicted = 1.0\n",
      "name = Alla; predicted = 1.0\n",
      "name = Harmony; predicted = 1.0\n",
      "name = Halley; predicted = 1.0\n",
      "name = Enrika; predicted = 1.0\n",
      "name = Hendrika; predicted = 1.0\n",
      "name = Gabey; predicted = 1.0\n",
      "name = Clemence; predicted = 1.0\n",
      "name = Batsheva; predicted = 1.0\n",
      "name = Ferdinanda; predicted = 1.0\n",
      "name = Vicky; predicted = 1.0\n",
      "name = Adrienne; predicted = 1.0\n",
      "name = Garey; predicted = 0.0\n",
      "name = Zacherie; predicted = 0.0\n",
      "name = Welsh; predicted = 0.0\n",
      "name = Chet; predicted = 0.0\n",
      "name = Felicio; predicted = 0.0\n",
      "name = Kaiser; predicted = 0.0\n",
      "name = Burgess; predicted = 0.0\n",
      "name = Saul; predicted = 0.0\n",
      "name = Louis; predicted = 0.0\n",
      "name = Miguel; predicted = 0.0\n",
      "name = Ryan; predicted = 0.0\n",
      "name = Reuven; predicted = 0.0\n",
      "name = Winn; predicted = 0.0\n",
      "name = Elwyn; predicted = 0.0\n",
      "name = Rafael; predicted = 0.0\n",
      "name = Worden; predicted = 0.0\n",
      "name = Olle; predicted = 0.0\n",
      "name = Jacques; predicted = 0.0\n",
      "name = Hiro; predicted = 0.0\n",
      "name = Maurie; predicted = 0.0\n",
      "name = Tynan; predicted = 0.0\n",
      "name = Jabez; predicted = 0.0\n",
      "name = Dante; predicted = 0.0\n",
      "name = Israel; predicted = 0.0\n",
      "name = Mace; predicted = 0.0\n",
      "name = Niven; predicted = 0.0\n",
      "name = Alexei; predicted = 0.0\n",
      "name = Tome; predicted = 0.0\n",
      "name = Alan; predicted = 0.0\n",
      "name = Zebulen; predicted = 0.0\n",
      "name = Meyer; predicted = 0.0\n",
      "name = Welch; predicted = 0.0\n",
      "name = Abdel; predicted = 0.0\n",
      "name = Olivier; predicted = 0.0\n",
      "name = Demetri; predicted = 0.0\n",
      "name = Lamar; predicted = 0.0\n",
      "name = Howie; predicted = 0.0\n",
      "name = Conway; predicted = 0.0\n",
      "name = Zeus; predicted = 0.0\n",
      "name = Kimmo; predicted = 0.0\n",
      "name = Raul; predicted = 0.0\n",
      "name = Jerri; predicted = 0.0\n",
      "name = Laurent; predicted = 0.0\n",
      "name = Parsifal; predicted = 0.0\n",
      "name = Luciano; predicted = 0.0\n",
      "name = Lorenzo; predicted = 0.0\n",
      "name = Jesus; predicted = 0.0\n",
      "name = Armstrong; predicted = 0.0\n",
      "name = Isaiah; predicted = 0.0\n",
      "name = Myke; predicted = 0.0\n",
      "name = Tudor; predicted = 0.0\n",
      "name = Neel; predicted = 0.0\n",
      "name = Jimmie; predicted = 0.0\n",
      "name = Lewis; predicted = 0.0\n",
      "name = Aditya; predicted = 0.0\n",
      "name = Griswold; predicted = 0.0\n",
      "name = Beck; predicted = 0.0\n",
      "name = Pavel; predicted = 0.0\n",
      "name = Gerrit; predicted = 0.0\n",
      "name = Spike; predicted = 0.0\n",
      "name = Laird; predicted = 0.0\n",
      "name = Byram; predicted = 0.0\n",
      "name = Shem; predicted = 0.0\n",
      "name = Saxe; predicted = 0.0\n",
      "name = Swen; predicted = 0.0\n",
      "name = Carl; predicted = 0.0\n",
      "name = Edwin; predicted = 0.0\n",
      "name = Ethan; predicted = 0.0\n",
      "name = Baird; predicted = 0.0\n",
      "name = Zebulon; predicted = 0.0\n",
      "name = Giacomo; predicted = 0.0\n",
      "name = Osgood; predicted = 0.0\n",
      "name = Randell; predicted = 0.0\n",
      "name = Stevie; predicted = 0.0\n",
      "name = Waylen; predicted = 0.0\n",
      "name = Zippy; predicted = 0.0\n",
      "name = Roscoe; predicted = 0.0\n",
      "name = Steven; predicted = 0.0\n",
      "name = Butch; predicted = 0.0\n",
      "name = Istvan; predicted = 0.0\n",
      "name = Charles; predicted = 0.0\n",
      "name = Kalil; predicted = 0.0\n",
      "name = Linoel; predicted = 0.0\n",
      "name = Burl; predicted = 0.0\n",
      "name = Enoch; predicted = 0.0\n",
      "name = Sven; predicted = 0.0\n",
      "name = Aloysius; predicted = 0.0\n",
      "name = Agamemnon; predicted = 0.0\n",
      "name = Jens; predicted = 0.0\n",
      "name = Sturgis; predicted = 0.0\n",
      "name = Bernard; predicted = 0.0\n",
      "name = Harlin; predicted = 0.0\n",
      "name = Rabbi; predicted = 0.0\n",
      "name = Riley; predicted = 0.0\n",
      "name = Beowulf; predicted = 0.0\n",
      "name = Jedediah; predicted = 0.0\n",
      "name = Glynn; predicted = 0.0\n",
      "name = Hailey; predicted = 0.0\n",
      "name = Nicolas; predicted = 0.0\n",
      "name = Davis; predicted = 0.0\n",
      "name = Rutger; predicted = 0.0\n",
      "name = Pace; predicted = 0.0\n",
      "name = Claudius; predicted = 0.0\n",
      "name = Sumner; predicted = 0.0\n",
      "name = Vachel; predicted = 0.0\n",
      "name = Bailey; predicted = 0.0\n",
      "name = Wojciech; predicted = 0.0\n",
      "name = Georges; predicted = 0.0\n",
      "name = Dionysus; predicted = 0.0\n",
      "name = Cornellis; predicted = 0.0\n",
      "name = Adnan; predicted = 0.0\n",
      "name = Merill; predicted = 0.0\n",
      "name = Rhett; predicted = 0.0\n",
      "name = Abel; predicted = 0.0\n",
      "name = Teodoro; predicted = 0.0\n",
      "name = Joab; predicted = 0.0\n",
      "name = Arel; predicted = 0.0\n",
      "name = Steve; predicted = 0.0\n",
      "name = Lincoln; predicted = 0.0\n",
      "name = Gunther; predicted = 0.0\n",
      "name = Cleland; predicted = 0.0\n",
      "name = Merell; predicted = 0.0\n",
      "name = Josef; predicted = 0.0\n",
      "name = Saunder; predicted = 0.0\n",
      "name = Elroy; predicted = 0.0\n",
      "name = Laurens; predicted = 0.0\n",
      "name = Bruno; predicted = 0.0\n",
      "name = Nikita; predicted = 0.0\n",
      "name = Lemar; predicted = 0.0\n",
      "name = Stevy; predicted = 0.0\n",
      "name = Blaine; predicted = 0.0\n",
      "name = Murphy; predicted = 0.0\n",
      "name = Ismail; predicted = 0.0\n",
      "name = Weidar; predicted = 0.0\n",
      "name = Florian; predicted = 0.0\n",
      "name = Reggy; predicted = 0.0\n",
      "name = Logan; predicted = 0.0\n",
      "name = Claudio; predicted = 0.0\n",
      "name = Hogan; predicted = 0.0\n",
      "name = Webb; predicted = 0.0\n",
      "name = Roger; predicted = 0.0\n",
      "name = Salem; predicted = 0.0\n",
      "name = Angelo; predicted = 0.0\n",
      "name = Odell; predicted = 0.0\n",
      "name = Mylo; predicted = 0.0\n",
      "name = Jessey; predicted = 0.0\n",
      "name = Aleks; predicted = 0.0\n",
      "name = Price; predicted = 0.0\n",
      "name = Merlin; predicted = 0.0\n",
      "name = Joel; predicted = 0.0\n"
     ]
    }
   ],
   "source": [
    "test_pred = MNB_clf.predict(X_test)\n",
    "for i in range (len(y_test)):\n",
    "    if y_test[i] != test_pred[i]:\n",
    "        print(\"name = {}; predicted = {}\".format(X_test_names[i], test_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Источников ошибок, судя по всему, несколько:\n",
    " * Некоторые н-грамы встречаются только один раз, например в Lucky, Luck - есть только одна н-грамма в тестовой выборке, в тоже  время ucky - есть среди мужских имен. \n",
    " * Созвучные имена - Emily (ж) и Emile(м). Robb(м) и Robby(ж), Robbi(ж), Robbin (ж), Robbyn(ж). \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_scores(pred, true):\n",
    "    acc = accuracy_score(pred,true)\n",
    "    acc = accuracy_score(pred, true)\n",
    "    micro_f1 = f1_score(pred, true, average = 'micro')\n",
    "    micro_p =  precision_score(pred, true, average = 'micro')\n",
    "    micro_rc =  recall_score(pred, true, average = 'micro' )\n",
    "    micro_r =  r2_score(pred, true)\n",
    "    macro_f1 = f1_score(pred, true, average = 'macro')\n",
    "    macro_p =  precision_score(pred, true, average = 'macro')\n",
    "    macro_r =  r2_score(pred, true)\n",
    "    macro_rc = recall_score(pred, true, average = 'macro' )\n",
    "    print('acc={0:1.4f}'.format(acc))\n",
    "    print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}, micro RC={3:1.4f}'.format(micro_f1, micro_p, micro_r, micro_rc))\n",
    "    print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}, macro RC={3:1.4f} \\n'.format(macro_f1, macro_p, macro_r, macro_rc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(fn:str):\n",
    "    \"\"\"\n",
    "        Прочитать файл и вернуть np.array(dtype=np.str())\n",
    "    \"\"\"\n",
    "    f = open(DATA_DIR + '/' + fn, 'r')\n",
    "    t = []\n",
    "    for i in f:\n",
    "        i = i.strip()\n",
    "        t.append(i)\n",
    "    rv = np.array(t, dtype=np.str)\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ngrams_list(l: list, n: int):\n",
    "    a = []\n",
    "    for i in l:\n",
    "        t = ngrams(i,n)\n",
    "        t2 = ''\n",
    "        for j in t:\n",
    "            t2 += ''.join((map(str,j))) + ' '\n",
    "        a.append(t2)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_dup_names(a: list, b:list):\n",
    "    for i in a:\n",
    "        if i in b:\n",
    "            a.remove(i)\n",
    "            b.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abcd': 0, 'bcde': 1, 'cdef': 2, 'erty': 3, 'qwer': 4, 'wert': 5}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = get_ngrams_list(['abcdef', 'qwerty'],4)\n",
    "cv = CountVectorizer(analyzer='word')\n",
    "cv.fit(t)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-d9b603314532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "t = np.array(['a','b','c','d'])\n",
    "np.delete(t['a'])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2 по обработке текстов\n",
    "\n",
    "Рассмотрим задачу бинарной классификации. Пусть дано два списка имен: мужские и женские имена. Требуется разработать классификатор, который по данному имени будет определять мужское оно или женское.\n",
    "\n",
    "Данные: \n",
    "* Женские имена: female.txt\n",
    "* Мужские имена: male.txt\n",
    "\n",
    "## Часть 1. Предварительная обработка данных\n",
    "\n",
    "1. Удалите неоднозначные имена (те имена, которые являются и мужскими, и женскими дновременно), если такие есть; \n",
    "2. Создайте обучающее и тестовое множество так, чтобы в обучающем множестве классы были сбалансированы, т.е. к классу принадлежало бы одинаковое количество имен;\n",
    "\n",
    "##  Часть 2. Базовый метод классификации\n",
    "\n",
    "Используйте метод наивного Байеса или логистическую регрессию для классификации имен: в качестве признаков используйте символьные $n$-граммы. Сравните результаты, получаемые при разных $n=2,3,4$ по $F$-мере и аккуратности. В каких случаях метод ошибается?\n",
    "\n",
    "Для генерации $n$-грамм используйте:\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "DATA_DIR='names_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "females = read_file('female.txt')\n",
    "males   = read_file('male.txt')\n",
    "females_uniq = np.setdiff1d(females, males)\n",
    "males_uniq = np.setdiff1d(males, females)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abcd': 0, 'bcde': 1, 'cdef': 2, 'erty': 3, 'qwer': 4, 'wert': 5}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(analyzer='word')\n",
    "cv.fit(t)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(t).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 2100\n",
    "TEST_SIZE = 440\n",
    "NGRAM_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_train, female_test = train_test_split(females_uniq, train_size = TRAIN_SIZE, test_size = TEST_SIZE)\n",
    "male_train, male_test = train_test_split(males_uniq, train_size = TRAIN_SIZE, test_size = TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_names = np.concatenate((female_train, male_train))\n",
    "X_test_names = np.concatenate((female_test, male_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.concatenate((np.zeros(TRAIN_SIZE),np.ones(TRAIN_SIZE))) \n",
    "y_test = np.concatenate((np.zeros(TEST_SIZE), np.ones(TEST_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_ngrams = get_ngrams_list(X_train_names,NGRAM_SIZE)\n",
    "X_test_ngrams = get_ngrams_list(X_test_names, NGRAM_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word')\n",
    "cv.fit(X_train_ngrams)\n",
    "X_train = cv.transform(X_train_ngrams)\n",
    "X_test = cv.transform(X_test_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200, 425)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_Scores\n",
      "acc=0.7748\n",
      "micro F1=0.7748, micro P=0.7748, micro R=0.0953, micro RC=0.7748\n",
      "macro F1=0.7745, macro P=0.7748, macro R=0.0953, macro RC=0.7759 \n",
      "\n",
      "TEST_Scores\n",
      "acc=0.7375\n",
      "micro F1=0.7375, micro P=0.7375, micro R=-0.0500, micro RC=0.7375\n",
      "macro F1=0.7375, macro P=0.7375, macro R=-0.0500, macro RC=0.7375 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "MNB_clf = MultinomialNB(alpha=1)\n",
    "MNB_clf.fit(X_train, y_train)\n",
    "train_predicted = MNB_clf.predict(X_train)\n",
    "print(\"TRAIN_Scores\")\n",
    "print_scores(train_predicted, y_train)\n",
    "print(\"TEST_Scores\")\n",
    "print_scores(MNB_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_scores(pred, true):\n",
    "    acc = accuracy_score(pred,true)\n",
    "    acc = accuracy_score(pred, true)\n",
    "    micro_f1 = f1_score(pred, true, average = 'micro')\n",
    "    micro_p =  precision_score(pred, true, average = 'micro')\n",
    "    micro_rc =  recall_score(pred, true, average = 'micro' )\n",
    "    micro_r =  r2_score(pred, true)\n",
    "    macro_f1 = f1_score(pred, true, average = 'macro')\n",
    "    macro_p =  precision_score(pred, true, average = 'macro')\n",
    "    macro_r =  r2_score(pred, true)\n",
    "    macro_rc = recall_score(pred, true, average = 'macro' )\n",
    "    print('acc={0:1.4f}'.format(acc))\n",
    "    print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}, micro RC={3:1.4f}'.format(micro_f1, micro_p, micro_r, micro_rc))\n",
    "    print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}, macro RC={3:1.4f} \\n'.format(macro_f1, macro_p, macro_r, macro_rc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(fn:str):\n",
    "    \"\"\"\n",
    "        Прочитать файл и вернуть np.array(dtype=np.str())\n",
    "    \"\"\"\n",
    "    f = open(DATA_DIR + '/' + fn, 'r')\n",
    "    t = []\n",
    "    for i in f:\n",
    "        i = i.strip()\n",
    "        t.append(i)\n",
    "    rv = np.array(t, dtype=np.str)\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ngrams_list(l: list, n: int):\n",
    "    a = []\n",
    "    for i in l:\n",
    "        t = ngrams(i,n)\n",
    "        t2 = ''\n",
    "        for j in t:\n",
    "            t2 += ''.join((map(str,j))) + ' '\n",
    "        a.append(t2)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_dup_names(a: list, b:list):\n",
    "    for i in a:\n",
    "        if i in b:\n",
    "            a.remove(i)\n",
    "            b.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abcd': 0, 'bcde': 1, 'cdef': 2, 'erty': 3, 'qwer': 4, 'wert': 5}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = get_ngrams_list(['abcdef', 'qwerty'],4)\n",
    "cv = CountVectorizer(analyzer='word')\n",
    "cv.fit(t)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-d9b603314532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "t = np.array(['a','b','c','d'])\n",
    "np.delete(t['a'])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
